========,1,preface.
In mathematics and computer programming, exponentiating by squaring is a general method for fast computation of large positive integer powers of a number, or more generally of an element of a semigroup, like a polynomial or a square matrix.
Some variants are commonly referred to as square-and-multiply algorithms or binary exponentiation.
These can be of quite general use, for example in modular arithmetic or powering of matrices.
For semigroups for which additive notation is commonly used, like elliptic curves used in cryptography, this method is also referred to as double-and-add.
========,2,Basic method.
The method is based on the observation that, for a positive integer "n", we have This method uses the bits of the exponent to determine which powers are computed.
This example shows how to compute ***formula*** using this method.
The exponent, 13, is 1101 in binary.
The bits are used in left to right order.
The exponent has 4 bits, so there are 4 iterations.
First, initialize the result to 1: ***formula***.
This may be implemented as the following recursive algorithm:  Although not tail-recursive, this algorithm may be rewritten into a tail recursive algorithm by introducing an auxiliary function:
The iterative version of the algorithm also uses a bounded auxiliary space, and is given by
========,2,2-ary method.
This algorithm calculates the value of x after expanding the exponent in base 2.
It was first proposed by Brauer in 1939.
In the algorithm below we make use of the following function f(0) = (k,0) and f(m) = (s,u) where m = u·2 with "u" odd.
***LIST***.
1. y := 1; i := l-1 For optimal efficiency, "k" should be the smallest integer satisfying
========,2,Sliding window method.
This method is an efficient variant of the 2-ary method.
For example, to calculate the exponent 398 which has binary expansion (110 001 110), we take a window of length 3 using the 2-ary method algorithm we calculate 1,x,x,x,x,x,x,x,x,x,x,x.
But, we can also compute 1,x,x,x,x,x,x,x,x, x which saves one multiplication and amounts to evaluating (110 001 110)n Here is the general algorithm:
***LIST***.
========,2,Montgomery's ladder technique.
Many algorithms for exponentiation do not provide defence against side-channel attacks.
Namely, an attacker observing the sequence of squarings and multiplications can (partially) recover the exponent involved in the computation.
This is a problem if the exponent should remain secret, as with many public-key cryptosystems.
A technique called Montgomery's Ladder addresses this concern.
Given the binary expansion of a positive, non-zero integer n=(n...n) with n=1 we can compute x as follows:
The algorithm performs a fixed sequence of operations (up to log n): a multiplication and squaring takes place for each bit in the exponent, regardless of the bit's specific value.
This specific implementation of Montgomery's ladder is not yet protected against cache timing attacks: memory access latencies might still be observable to an attacker as you access different variables depending on the value of bits of the secret exponent.
========,2,Fixed base exponent.
There are several methods which can be employed to calculate x when the base is fixed and the exponent varies.
As one can see, precomputations play a key role in these algorithms.
========,3,Yao's method.
Yao's method is orthogonal to the -ary method where the exponent is expanded in radix and the computation is as performed in the algorithm above.
Let ", ", ", and " be integers.
Let the exponent "" be written as Let .
Then the algorithm uses the equality Given the element " of , and the exponent " written in the above form, along with the precomputed values the element is calculated using the algorithm below.
If we set and then the 's are simply the digits of in base .
Yao's method collects in u first those which appear to the highest power ; in the next round those with power are collected in as well etc.
The variable y is multiplied times with the initial , times with the next highest powers etc.
The algorithm uses multiplications and elements must be stored to compute .
========,2,Further applications.
The same idea allows fast computation of large exponents modulo a number.
Especially in cryptography, it is useful to compute powers in a ring of integers modulo "q".
It can also be used to compute integer powers in a group, using the rule The method works in every semigroup and is often used to compute powers of matrices.
For example, the evaluation of would take a very long time and lots of storage space if the naïve method were used: compute 13789 then take the remainder when divided by 2345.
Even using a more effective method will take a long time: square 13789, take the remainder when divided by 2345, multiply the result by 13789, and so on.
This will take less than ***formula*** modular multiplications.
Applying above "exp-by-squaring" algorithm, with "*" interpreted as "x"*"y" = "xy" mod 2345 (that is a multiplication followed by a division with remainder) leads to only 27 multiplications and divisions of integers which may all be stored in a single machine word.
========,2,Example implementations.
========,3,Computation by powers of 2.
This is a non-recursive implementation of the above algorithm in Ruby.
In most statically typed languages, result=1 must be replaced with code assigning an identity matrix of the same size as x to result to get a matrix exponentiating algorithm.
In Ruby, thanks to coercion, result is automatically upgraded to the appropriate type, so this function works with matrices as well as with integers and floats.
Note that n=n-1 is redundant when n=n/2 implicitly rounds towards zero, as lower level languages would do.
n[0] is the rightmost bit of the binary representation of n, so if it is 1, the number is odd, if it is zero, the number is even.
========,3,Calculation of products of powers.
Exponentiation by squaring may also be used to calculate the product of 2 or more powers.
If the underlying group or semigroup is commutative then it is often possible to reduce the number of multiplications by computing the product simultaneously.
========,4,Example.
The formula a×b may be calculated within 3 steps:
so one gets eight multiplications in total.
A faster solution is to calculate both powers simultaneously:
which needs only 6 multiplications in total.
Note that a×b is calculated twice; the result could be stored after the first calculation, which reduces the count of multiplication to 5.
Example with numbers:
Calculating the powers simultaneously instead of calculating them separately always reduces the count of multiplications if at least two of the exponents are greater than 1.
========,4,Using transformation.
The example above a×b may also be calculated with only 5 multiplications if the expression is transformed before calculation:
a×b = a×(ab) with ab := a×b
Generalization of transformation shows the following scheme:<br>
For calculating a×b×...×m×n<br>
1st: define ab := a×b, abc = ab×c, ...<br>
2nd: calculate the transformed expression a×ab×...×abc..m×abc..mn
Transformation before calculation often reduces the count of multiplications
but in some cases it also increases the count (see the last one of the examples below),
so it may be a good idea to check the count of multiplications before using the transformed expression for calculation.
========,2,Signed-digit recoding.
In certain computations it may be more efficient to allow negative coefficients and hence use the inverse of the base, provided inversion in is 'fast' or has been precomputed.
For example, when computing the binary method requires multiplications and squarings.
However one could perform squarings to get and then multiply by to obtain .
To this end we define the signed-digit representation of an integer in radix as  Another algorithm by Koyama and Tsuruoka does not require the condition that ***formula***; it still minimizes the Hamming weight.
========,2,Alternatives and generalizations.
Exponentiation by squaring can be viewed as a suboptimal addition-chain exponentiation algorithm: it computes the exponent via an addition chain consisting of repeated exponent doublings (squarings) and/or incrementing exponents by "one" (multiplying by "x") only.
More generally, if one allows "any" previously computed exponents to be summed (by multiplying those powers of "x"), one can sometimes perform the exponentiation using fewer multiplications (but typically using more memory).
The smallest power where this occurs is for "n"=15:
In general, finding the "optimal" addition chain for a given exponent is a hard problem, for which no efficient algorithms are known, so optimal chains are typically only used for small exponents (e.g.
in compilers where the chains for small powers have been pre-tabulated).
However, there are a number of heuristic algorithms that, while not being optimal, have fewer multiplications than exponentiation by squaring at the cost of additional bookkeeping work and memory usage.
Regardless, the number of multiplications never grows more slowly than Θ(log "n"), so these algorithms only improve asymptotically upon exponentiation by squaring by a constant factor at best.
