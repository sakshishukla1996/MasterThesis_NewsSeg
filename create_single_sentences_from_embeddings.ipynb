{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentences', 'language', 'embeddings', 'labels', 'keywords'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load(files[0])\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/213 [03:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:424] . unexpected pos 3392 vs 3286",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/dev/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dev/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:588] . PytorchStreamWriter failed writing file data/0: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 21\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(thresh, emb.shape, labs.shape, out_root / f\"{file.stem}_{isx}.pt\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m new_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m: sent,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m: a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m][isx],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m: a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m][isx] \n\u001b[1;32m     20\u001b[0m }\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43misx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# if running_pointer>100:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dev/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dev/lib/python3.10/site-packages/torch/serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 3392 vs 3286"
     ]
    }
   ],
   "source": [
    "inppath = Path(\"/disk1/data/preproc_sonar/dw_2019/de\")\n",
    "files = list(inppath.iterdir())\n",
    "OUT_ROOT = \"/data/preproc_sonar_single\"\n",
    "for file in tqdm(files):\n",
    "    out_root = Path(OUT_ROOT) / file.parent.stem\n",
    "    a = torch.load(file)\n",
    "    running_pointer=0\n",
    "    for isx, sent in tqdm(enumerate(a['sentences']), total=len(a['sentences']), leave=False):\n",
    "        thresh = len(sent)\n",
    "        emb = a['embeddings'][running_pointer:running_pointer+thresh]\n",
    "        labs = a['labels'][running_pointer:running_pointer+thresh]\n",
    "        running_pointer+=thresh\n",
    "        # print(thresh, emb.shape, labs.shape, out_root / f\"{file.stem}_{isx}.pt\")\n",
    "        new_dict = {\n",
    "            'sentences': sent,\n",
    "            'language': a['language'][isx],\n",
    "            'embeddings': emb.cpu(),\n",
    "            'labels': labs.cpu(),\n",
    "            'keywords': a['keywords'][isx] \n",
    "        }\n",
    "        torch.save(new_dict, out_root / f\"{file.stem}_{isx}.pt\")\n",
    "        # if running_pointer>100:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Der Regierung liege \"keine Gesamtübersicht über die Zahl der in Erstaufnahmeeinrichtungen untergebrachten Asylbewerber vor\", schrieb der Parlamentarische Staatssekretär im Bundesinnenministerium, Ole Schröder (CDU) an die Grünen-Abgeordnete Renate Künast, die sich mit einer entspechenden Anfrage gemeldet hatte.',\n",
       "  'Der Regierung sei auch nicht bekannt, wieviele Menschen von den ersten Einrichtungen dann auf die Kommunen verteilt worden seien, so Schröder.',\n",
       "  'Er verwies allerdings darauf, dass zwischen Anfang Januar und dem 2. November gut 770.000 Flüchtlinge im Rahmen des sogenannten EASY-Verfahrens verteilt worden seien.',\n",
       "  'Verständnis und Kritik\\nDie Grünen-Abgeordnete Künast sagte, jeder habe Verständnis dafür, dass es schwierig sei, die Zahl der Flüchtlinge in Deutschland präzise angeben zu können.',\n",
       "  'Dass die Bundesregierung \"aber schlicht gar nicht weiß, wie viele Menschen sich zur Zeit in den Erstaufnahmeeinrichtungen aufhalten, ist peinlich\".',\n",
       "  'Wie könne eine vernünftige Flüchtlingspolitik gelingen, wenn schon die statistische Erfassung nicht einmal im Ansatz funktioniere, fragte Künast.',\n",
       "  'Sie betonte, statt täglich \"mit neuen Gesetzesverschärfungen zu marodieren\", sollten Innenminister Thomas de Maizière und Kanzleramtsminister Peter Altmaier, \"lieber ihre Hausaufgaben machen\".',\n",
       "  'Die Schutzsuchenden müssten versorgt und registriert werden und ihre Anträge müssten bearbeitet werden, mahnte die frühere Verbraucherschutzministerin.',\n",
       "  'Debatte über verschärfte Asylregeln hält an\\nDe Maizière hatte in den vergangenen Tagen mit Verschärfungen bei der Asylpolitik für Unmut auch in der Regierung gesorgt.',\n",
       "  'Die Neuerungen betrafen vor allem die Situation der in Deutschland um Asyl bittenden syrischen Flüchtlinge.',\n",
       "  'In einer Bundestagsdebatte am Mittwoch hatte der Bundesinnenminister seine Entscheidung verteidigt, das Dublin-Verfahren wieder für syrische Asylbewerber anzuwenden.',\n",
       "  '\"Wir verfolgen das Ziel, damit wieder zu geordneten Verfahren bei der Einreise zurückzukehren\", sagte de Maizière im Bundestag.',\n",
       "  'Asylsuchende aus dem Bürgerkriegsland können demnach in den Staat zurückgeschickt werden, über den sie in die EU eingereist sind.',\n",
       "  'Wegen der stark angestiegenen Flüchtlingszahlen habe man dieses Vorgehen bei Syrern im August vorübergehend gestoppt, es im Oktober aber wieder eingeführt, sagte de Maizière.',\n",
       "  'Die SPD hatte überrascht auf die Entscheidung reagiert, auch weil sie sehr kurzfristig getroffen wurde und weder mit dem Kanzleramt noch mit dem Koalitionspartner abgesprochen war.',\n",
       "  'bri/haz (dpa, epd, afp)'],\n",
       " 'language': 'de',\n",
       " 'embeddings': tensor([[-1.7036e-02,  8.3200e-03, -6.4064e-03,  ...,  2.3852e-03,\n",
       "           5.7572e-03,  8.4075e-03],\n",
       "         [ 1.3209e-04,  2.7983e-03,  5.2870e-03,  ...,  7.7439e-03,\n",
       "           1.0632e-02,  1.1417e-02],\n",
       "         [-7.5596e-03,  1.4858e-03, -3.7610e-03,  ...,  5.1553e-03,\n",
       "           8.1477e-05,  2.5922e-03],\n",
       "         ...,\n",
       "         [-1.1389e-03,  2.8234e-03, -2.1170e-03,  ...,  3.8405e-03,\n",
       "           8.6857e-04,  1.6106e-03],\n",
       "         [-1.7007e-03,  7.6482e-03,  1.1647e-02,  ...,  6.1385e-03,\n",
       "           2.6306e-05, -2.4999e-03],\n",
       "         [ 4.9759e-03,  1.9950e-03, -5.9937e-03,  ...,  2.8567e-03,\n",
       "          -4.7690e-03, -2.3330e-03]]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'keywords': ['Flüchtlingspolitik', 'Thomas de Maiziere', 'Renate Künast']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
